# Bulk Data Processing Workflow

**Video Tutorial:** [Watch](https://www.youtube.com/watch?v=qR_nJLv_Z9g) ![views](https://img.shields.io/youtube/views/qR_nJLv_Z9g?style=flat&label=)

<p align="center">
  <a href="https://www.youtube.com/watch?v=qR_nJLv_Z9g">
    <img src="https://img.youtube.com/vi/qR_nJLv_Z9g/maxresdefault.jpg" alt="Watch the tutorial" width="400">
  </a>
</p>

Eliminates copy-pasting data rows for analysis one by one. Process hundreds of rows automatically instead of manual repetition.

## What it does

ğŸ”„ Batch process rows
ğŸ“‚ Categorize content
ğŸ” Extract data
ğŸ”— Combine sources

## Who it's for

Anyone doing repetitive data tasks: content managers, analysts, marketers processing large datasets for categorization, extraction, or analysis.

## Workflow Preview

<p align="center">
  <img src="assets/cover.png" alt="Workflow Preview" width="500">
</p>




## Requirements

- n8n ([cloud](https://n8n.cloud) or [self-hosted](https://youtu.be/kq5bmrjPPAY))
- Data source (Google Sheets, CSV, etc.)
- LLM access (OpenAI, Groq, Claude, etc.)

## Setup

1. Copy the JSON workflow into n8n (`Ctrl+V` on canvas)
2. Connect your data source and LLM
3. Run

## Structured Output

See `.st.json` files for JSON Schema examples.
